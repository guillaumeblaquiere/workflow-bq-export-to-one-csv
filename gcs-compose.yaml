main:
  steps:
    - assignStep:
        assign:
          - bucket: "<YOUR BUCKET>"
          - projectid: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")} # or "<YOUR PROJECT ID>"
          - prefix: "<YOUR FILE PREFIX>"
          - query: "<YOUR BIGQUERY QUERY>"
          - finalFileName: "<YOUR OUTPUT FILE NAME>"
          - listResult:
              nextPageToken: ""
    - export-query:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: ${projectid}
          body:
            query: ${"EXPORT DATA OPTIONS( uri='gs://" + bucket + "/" + prefix + "*.csv', format='CSV', overwrite=true,header=false) AS " + query}
            useLegacySql: false
    - waitForGCS: # fix latency issue with Cloud Storage
        call: sys.sleep
        args:
          seconds: 1
          #init final file # Issue for now. Connector soon usable
          #    - create-final-file:
          #        call: googleapis.storage.v1.objects.insert
          #        args:
          #          bucket: ${bucket}
          #          name: ${finalFileName}
          #          userProject: ${projectid}
          #          body:
          #            name: ${finalFileName}
    - create-final-file:
        call: http.post
        args:
          url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + bucket + "/o?name=" + finalFileName + "&uploadType=media"}
          auth:
            type: OAuth2
          body:
    - composefiles:
        call: list_and_compose_file
        args:
          pagetoken: ${listResult.nextPageToken}
          bucket: ${bucket}
          prefix: ${prefix}
          projectid: ${projectid}
          finalFileName: ${finalFileName}
        result: listResult
    - missing-files: # Non recursive loop, to prevent depth errors
        switch:
          - condition: ${"nextPageToken" in listResult}
            next: composefiles


list_and_compose_file:
  params:
    - pagetoken
    - bucket
    - prefix
    - projectid
    - finalFileName
  steps:
    - list-files:
        call: googleapis.storage.v1.objects.list
        args:
          bucket: ${bucket}
          pageToken: ${pagetoken}
          prefix: ${prefix}
          maxResults: 62
        result: listResult
    - init-iter:
        assign:
          - finalFileFormatted:
              name: ${finalFileName}
          - fileList:
              - ${finalFileFormatted}
    - process-files:
        for:
          value: file
          in: ${listResult.items}
          steps:
            - concat-file:
                assign:
                  - fileFormatted:
                      name: ${file.name}
                  - fileList: ${list.concat(fileList, fileFormatted)}
            - test-concat:
                switch:
                  - condition: ${len(fileList) == 32}
                    steps:
                      - compose-files:
                          call: compose_file
                          args:
                            fileList: ${fileList}
                            projectid: ${projectid}
                            bucket: ${bucket}
                            finalFileName: ${finalFileName}
                          next: init-for-iter
                      - init-for-iter:
                          assign:
                            - fileList:
                                - ${finalFileFormatted}
    - finish-compose: # Process the latest files in the fileList buffer
        switch:
          - condition: ${len(fileList) > 1} # If there is more than the finalFileName in the list
            steps:
              - last-compose-files:
                  call: compose_file
                  args:
                    fileList: ${fileList}
                    projectid: ${projectid}
                    bucket: ${bucket}
                    finalFileName: ${finalFileName}
    - return-step:
        return: ${listResult}


compose_file:
  params:
    - fileList
    - projectid
    - bucket
    - finalFileName
  steps:
    - compose:
        call: googleapis.storage.v1.objects.compose
        args:
          destinationBucket: ${bucket}
          destinationObject: ${text.replace_all(finalFileName,"/","%2F")} # URL encoding function soon available
          body:
            sourceObjects: ${fileList}